{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Poloniex API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# Function to make API requests to Poloniex\n",
    "def poloniex(endpoint: str, params: dict = {}):\n",
    "    url = 'https://api.poloniex.com/'\n",
    "    final_url = url + endpoint\n",
    "    \n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.get(final_url, params=params)\n",
    "\n",
    "        # Check for a successful response\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Retrieve Ticker Data and Save to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get market tickers and create a DataFrame\n",
    "market_tickers = poloniex(f'markets/ticker24h')\n",
    "df = pd.DataFrame(market_tickers)\n",
    "\n",
    "# Save the data to a CSV file named with the current date\n",
    "today = date.today()\n",
    "df.to_csv('Market-Data-Preprocessing\\New-Api-Version\\DataBase\\Ticker24h/'+ str(today) + '.csv', index=False)\n",
    "\n",
    "# Read the CSV file for further processing\n",
    "df = pd.read_csv('Market-Data-Preprocessing\\New-Api-Version\\DataBase\\Ticker24h/2023-10-27.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Data Cleaning and Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove test rows with specific prefixes\n",
    "test_prefixes = ['POLOTEST1', 'POLOTEST2', 'POLOTEST3', 'POLOTEST4']\n",
    "df = df[~df['symbol'].str.startswith(tuple(test_prefixes))]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Identify unique postfixes and adjust the data\n",
    "unique_postfixes = df['symbol'].str.split('_').str[1].unique()\n",
    "\n",
    "# Identify converting rates for currencies\n",
    "# (Assumes that there is a base currency, represented by 'base_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Calculate Adjusted Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjusted volumes based on converting rates\n",
    "df['adjusted_amount'] = df['amount'] * df['symbol'].str.split('_').str[1].map(converter_dict)\n",
    "\n",
    "# Extract the coin names\n",
    "df['coin'] = df['symbol'].str.split('_').str[0]\n",
    "\n",
    "# Group by coin and calculate total adjusted volume\n",
    "volumes_df = df.groupby('coin').agg({'adjusted_amount': 'sum'})\n",
    "volumes_df.reset_index(drop=False, inplace=True)\n",
    "volumes_df.rename(columns={'adjusted_amount': 'volume'}, inplace=True)\n",
    "\n",
    "# Save the volumes data to a CSV file named with the current date\n",
    "volumes_df.to_csv('Market-Data-Preprocessing\\New-Api-Version\\DataBase\\Volumes/'+ str(today) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Aggregate Volumes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate volumes data from multiple CSV files\n",
    "folder_path = 'Market-Data-Preprocessing\\New-Api-Version\\DataBase/Volumes'\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "volumes_dicts = []\n",
    "\n",
    "# Loop through CSV files and create dictionaries\n",
    "for csv_file in csv_files:\n",
    "    # Read each CSV file\n",
    "    volumes_df = pd.read_csv(os.path.join(folder_path, csv_file))\n",
    "    volumes_dict = volumes_df.set_index('coin')['volume'].to_dict()\n",
    "    volumes_dicts.append(volumes_dict)\n",
    "\n",
    "# Combine dictionaries to get final volumes\n",
    "final_volumes_dict = {}\n",
    "for d in volumes_dicts:\n",
    "    for key, value in d.items():\n",
    "        final_volumes_dict[key] = final_volumes_dict.get(key, 0) + value\n",
    "\n",
    "# Create a DataFrame from the final volumes dictionary\n",
    "final_volumes_df = pd.DataFrame.from_dict(final_volumes_dict, orient='index', columns=['volumes'])\n",
    "final_volumes_df.reset_index(inplace=True)\n",
    "final_volumes_df.columns = ['coin', 'volumes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6: Display Top N Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the top N volumes from a DataFrame\n",
    "def top_n_volumes(dataframe, n=10, column_name='volumes'):\n",
    "    sorted_dataframe = dataframe.sort_values(by=column_name, ascending=False)\n",
    "    top_n_rows = sorted_dataframe.head(n)\n",
    "    top_n_rows.reset_index(drop=True, inplace=True)\n",
    "    return top_n_rows\n",
    "\n",
    "# Display the top N volumes\n",
    "print(top_n_volumes(final_volumes_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 7: Get Coin Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get features for specific coins\n",
    "def get_coins_features(coin_list, columns_list=['adjusted_amount']):\n",
    "    grouped = df.groupby('coin')\n",
    "    \n",
    "    for coin in coin_list:\n",
    "        selected_indices = grouped.get_group(coin).index\n",
    "        print(f\"Indices with {coin} as prefix:\")\n",
    "        for idx in selected_indices:\n",
    "            print(df.loc[idx, 'symbol'], \": \", df.loc[idx, columns_list])\n",
    "            print(' -------------------------- ')\n",
    "\n",
    "# Example usage: Get features for coins with the prefix 'NFT'\n",
    "get_coins_features(['NFT'], ['adjusted_amount', 'amount', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 8: Fetch Market Chart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch market chart data for symbols in the top list\n",
    "number_of_coins = 20\n",
    "top_df = top_n_volumes(final_volumes_df, number_of_coins)\n",
    "top_list = top_df['coin'].tolist()\n",
    "symbols_list = [coin + '_' + base_value for coin in top_list]\n",
    "\n",
    "# Fetch market chart data for each symbol in the list\n",
    "for symbol in symbols_list:\n",
    "    print(f'markets/{symbol}/candles')\n",
    "    market_chart = poloniex(f'markets/{symbol}/candles', {'interval': 'HOUR_6'})\n",
    "    chart_df = pd.DataFrame(market_chart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
